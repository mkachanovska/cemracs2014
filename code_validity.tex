\documentclass[11pt]{amsart}
\usepackage{geometry}                % See geometry.pdf to learn the layout options. There are lots.
\geometry{letterpaper}                   % ... or a4paper or a5paper or ... 
%\geometry{landscape}                % Activate for for rotated page geometry
%\usepackage[parfill]{parskip}    % Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{epstopdf}
\usepackage{tikz}
\usepackage{pgfplots}
%\usepackage{slashbox}
\newtheorem{theor}{Theorem}
\newtheorem{Lemma}{Lemma}
\newtheorem{remark}{Remark}
\usepackage[font=small,skip=0pt]{caption}
\setlength{\abovecaptionskip}{20pt plus 3pt minus 2pt}
\newtheorem{assumption}{Assumption}\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tif`.png}
                                        % Activate to display a given date or no date
\newcommand{\bs}{\left\{}
\newcommand{\es}{\right.}
\newcommand{\ba}{\begin{array}}
\newcommand{\ea}{\end{array}}
\newcommand{\be}{\begin{equation}}
\newcommand{\ee}{\end{equation}}
\newcommand{\ora}{\overrightarrow}
\newcommand{\x}{{\bf x}}
\newcommand{\E}{{\bf E}}
\newcommand{\n}{{\bf n}}
\newcommand{\f}{{\bf f}}
\begin{document}
\begin{subsection}{Discretization}
Clearly, $u$ solves the well-posed problem 
\begin{align*}
a(u, v)=(f,v)\text{ for all } v=(v_{1},v_{2})^{T}\in V^2, 
\end{align*}
if and only if (this can be easily checked)
\begin{align*}
a(u,(v_{1},0)^{T})=(f,(v_{1},0)^{T}),\\
a(u,(0,v_{2})^{T})=(f,(0,v_{2})^{T}).
\end{align*}


\begin{remark}
The application of the above to the variational formulation (\ref{}) allows to obtain the following system of two equations:
\[\begin{array}{l}
i\theta \displaystyle \int_{-L}^H (E_2' -\imath\theta E_1)\overline{\tilde E_1} - \int_{-L}^H \left((\epsilon_0 +\imath\nu \operatorname{Id}) \E\right)_{1} \overline{\tilde E}_{1}
=0
\end{array}
\]
and 
\begin{align}
\label{eq:E2}
\begin{array}{l}
\displaystyle \int_{-L}^H (E_2' -\imath\theta E_1)\tilde {E_2'} - \int_{-L}^H\left( (\epsilon_0 +\imath\nu\operatorname{Id}) \E\right)_{2}\overline{\tilde{E}}_{2}
\\ \displaystyle  - \imath \sqrt{\alpha(-L)} E_2 (-L) \tilde E_2 (-L) = -g_{inc} (-L) \overline{( \tilde E_2(-L) )} 
\end{array}
\end{align}
Let us consider the case $\theta=0$; in particular, from the first equation we obtain:
\begin{align*}
\int_{-L}^{H}\left((\alpha+i\nu)E_{1}+i\delta E_{2}\right)\overline{\tilde E}_{1}=0
\end{align*}
for all ${\tilde E}_{1}\in L_{2}(\Omega)$. 

If the following operator
\begin{align*}
M\psi = \frac{i\delta}{(\alpha+i\nu)}\psi
\end{align*}
defines an isomorphism from $L_{2}(\Omega)$ to $L_{2}(\Omega)$, it can be shown that 
$ \frac{i\delta}{(\alpha+i\nu)}\left((\alpha+i\nu)E_{1}+i\delta E_{2}\right)$ also belongs to $L_{2}(\Omega)$ and equals zero.

Hence, we can add the second expression (\ref{eq:E2}) to
\begin{align*}
\int_{-L}^{H}\left(i\delta E_{1}-\delta^2(\alpha+i\nu)^{-1} E_{2}\right)\overline{\tilde E}_{2}=0
\end{align*}
to obtain the variational formulation for $E_{2}$, that will coincide with the variational formulation for the Helmholtz equation, and thus will be well-posed (see the thesis of L.M.I.G.).

Thus we can repeat the estimates from the above-mentioned thesis, and estimate $\|E_{1}\|_{L_{2}}$ in terms of $\|E_{2}\|_{L_{2}}$.
\end{remark}



Introducing two basis spaces, $V_{E_{1}}=\{\psi_{j}\}_{j=1}^{N_{1}}$ and $V_{E_{2}}=\{\phi_{i}\}_{i=1}^{N_{2}}$, we look for the solution of the problem (\ref{}) in the form:
\begin{align*}
E_{1}=\sum\limits_{k=1}^{N_{1}}e_{1k}\psi_{k},\; E_{2}=\sum\limits_{k=1}^{N_{2}}e_{2k}\phi_{k}.
\end{align*}
Substituting $\tilde{E}_{1}=\psi_{m}, \; m=1,\ldots,N_{1}$ and $\tilde{E}_{2}=0$ into the variational formulation (\ref{}), we obtain:
\begin{align*}
i\theta\sum\limits_{k=1}^{N_{2}}e_{2k}\int\limits_{-L}^{H}\phi'_{k}\bar{\psi}_{m}dx+\theta^2\sum\limits_{k=1}^{N_{1}}e_{1k}\int\limits_{-L}^{H}\psi_{k}\bar{\psi}_{m}dx\\
-\sum\limits_{k=1}^{N_{1}}e_{1k}\int\limits_{-L}^{H}(\alpha(x)+i\nu)\psi_{k}\bar{\psi}_{m}dx-i\sum\limits_{1}^{N_{2}}e_{2k}\int\limits_{-L}^{H}\delta(x)\phi_{k}(x)\bar{\psi}_{m}dx=0.
\end{align*}
Similarly, for $\tilde{E}_{1}=0$ and $\tilde{E}_{2}=\phi_{\ell},\; \ell=1,\ldots, N_{2}$:
\begin{align*}
\sum\limits_{k=1}^{N_{2}}e_{2k}\int\limits_{-L}^{H}\phi'_{k}(x)\bar{\phi}'_{\ell}(x)dx-i\theta\sum\limits_{k=1}^{N_{1}}e_{1k}\int\limits_{-L}^{H}\psi_{k}(x)\bar{\phi}'_{\ell}(x)dx\\
+i
\sum\limits_{k=1}^{N_{1}}e_{1k}\int\limits_{-L}^{H}\delta(x)\psi_{k}\bar{\phi}_{m}dx-\sum\limits_{k=1}^{N_{2}}e_{2k}\int\limits_{-L}^{H}(\alpha(x)+i\nu)\phi_{k}\bar{\phi}_{m}dx\\
-
i\lambda\sum\limits_{k=1}^{N_{2}}e_{2k}\phi_{k}(-L)\bar{\phi}_{m}(-L)=-g_{inc}(x)\bar{\phi}_{m}(-L).
\end{align*}
After introduction 
\begin{align*}
\left(K^{\psi,\phi'}\right)_{mk}=\int\limits_{-L}^{H}\bar{\psi}_{m}\phi'_{k}dx,\qquad \left(M^{\psi}\right)_{mk}=\int\limits_{-L}^{H}\psi_{k}\bar{\psi}_{m}dx,\\
\left(M^{\alpha,\psi}\right)_{mk}=\int\limits_{-L}^{H}(\alpha(x)+i\nu)\psi_{m}\bar{\psi}_{k}dx, \qquad \left(M^{\delta,\psi,\phi}\right)_{mk}=\int\limits_{-L}^{H}\delta(x)\bar{\psi}_{m}\phi_{k}dx,\\
K_{\ell k}=\int\limits_{-L}^{H}\phi'_{k}(x)\bar{\phi}'_{\ell}(x)dx,\qquad \left(M^{\alpha,\phi}\right)_{\ell k}=\int\limits_{-L}^{H}(\alpha(x)+i\nu)\bar{\phi}_{\ell}\phi_{k}dx,\\
I_{km}^{\Gamma}=\bar{\phi}_{m}(-L)\phi_{k}(-L),\\
\boldsymbol{e}_{1}=\left(e_{11},\ldots,e_{1 N_{1}}\right)^{T},\; \boldsymbol{e}_{2}=\left(e_{21},\ldots,e_{2 N_{1}}\right)^{T},\\
\boldsymbol{0}_{n} \text{ is an $n$-dimensional zero column vector}.
\end{align*}
the above system of equations can be rewritten in an antisymmetric block form:
\begin{align*}
\left(\begin{matrix}
\theta^2 M_{\psi}-M^{\alpha,\psi} & i\theta K^{\psi,\phi'}-i M^{\delta,\psi,\phi} \\
-i\theta (K^{\psi,\phi'})^{*}+i (M^{\delta,\psi,\phi})^{*} & K-M^{\alpha,\phi}-i\lambda I^{\Gamma}
\end{matrix}\right)
\left(
\begin{matrix}
\boldsymbol{e}_1\\
\boldsymbol{e}_2
\end{matrix}
\right)=-g_{inc}(-L)
\left(
\begin{matrix}
\boldsymbol{0}_{N_{1}}\\
\bar{\phi}_{1}(-L)\\
\bar{\phi}_{2}(-L)\\
\vdots\\
\bar{\phi}_{N_{2}}(-L)
\end{matrix}
\right).
\end{align*}
This expression greatly simplifies when choosing $V_{E_{1}}=V_{E_{2}}=\left(\phi_{m}\right)_{m=1}^{N_{2}}$ and in the case $\theta=0$:
\begin{align}
\label{eq:simple_system}
\left(\begin{matrix}
M^{\alpha,\phi} & i M^{\delta,\phi,\phi} \\
i (M^{\delta,\phi,\phi})^{*} & K-M^{\alpha,\phi}-i\lambda I^{\Gamma}
\end{matrix}\right)
\left(
\begin{matrix}
\boldsymbol{e}_1\\ 
\boldsymbol{e}_2
\end{matrix}
\right)=-g_{inc}(-L)
\left(
\begin{matrix}
\boldsymbol{0}_{N_{1}}\\
\bar{\phi}_{1}(-L)\\
\bar{\phi}_{2}(-L)\\
\vdots\\
\bar{\phi}_{N_{2}}(-L)
\end{matrix}
\right).
\end{align}
\end{subsection}
\begin{subsection}{Numerical Experiments}
We implemented the above scheme for a simple case of $P_{1}$-space used for the approximation of $E_{1}$ and $E_{2}$, $\theta=0$. 

To check the validity of the code, we perform a numerical experiment with (formally chosen) parameters:
\begin{align}
\label{eq:parameters}
\alpha(x)=x^2+1,\qquad \delta(x)=\left(\alpha^2+x\alpha\right)^{\frac{1}{2}}.
\end{align}
Additionally, the boundary conditions read as 
\begin{align}
\label{eq:bcs}
\partial_{1}E_{2}(-L)+2iE_{2}(-L)=2iAi(-L)+Ai'(-L),\\
\partial_{1}E_{2}(H)=0,
\end{align}
where $Ai(x)$ is the Airy function.

It can be shown that 
\begin{align*}
E_{2}=Ai(x),\\
E_{1}=-i\frac{\delta(x)}{\alpha(x)}Ai(x)
\end{align*}
is the solution to the problem with parameters (\ref{eq:parameters}) with the boundary condition (\ref{eq:bcs}).

In Figure \ref{fig:conv_rate} we demonstrate the convergence rates for this problem, with 
\begin{align*}
\|E_{1}-E_{1}^{c}\|_{L_{2}(\Omega)}=\left(\int\limits_{\Omega}\left|E_{1}(x)-\sum\limits_{k=0}^{N}E_{1i}\phi_{i}\right|^2dx\right),
\end{align*}
where $\left(\phi_{i}\right)_{i=1}^{N}$ are $P_{1}$-finite elements and $E_{1}(x)$ is a known analytic solution. Similarly $\|E_{2}-E_{2}^{c}\|_{L_{2}(\Omega)}$ and $\|E_{2}-E_{2}^{c}\|_{H_{1}(\Omega)}$ are defined. 

\begin{figure}
\begin{tikzpicture}
    \begin{loglogaxis}[
        xlabel=$h$,
        ylabel=$Error$,
        legend style={
at={(0.2,1.5)},
legend pos= south east,
anchor=south east, 
draw=none
}
]
    \addplot[mark=*,blue] table {pics/E1L2.dat}; 
    \addlegendentry{$\|E_{1}-E_{1}^{c}\|_{L_{2}}$};
    \addplot[mark=*,red] table {pics/E2H1.dat};
        \addlegendentry{$\|E_{2}-E_{2}^{c}\|_{H_{1}}$};
        
          \addplot[mark=*,cyan] table {pics/E2L2.dat};
        \addlegendentry{$\|E_{2}-E_{2}^{c}\|_{L_{2}}$};  
        \addplot[dotted] table{pics/E_h2.dat};
         \addlegendentry{$O(h^2)$};
         \addplot[dashed] table{pics/H.dat};
         \addlegendentry{$O(h)$};
    \end{loglogaxis}
    \end{tikzpicture}
    \caption{Convergence rates for the problem with parameters (\ref{eq:parameters}) with the boundary condition (\ref{eq:bcs}).}
    \label{fig:conv_rate}
\end{figure}

Note that in the last 3 experiments the error of the solution of the system of equations, namely $\|Ae-r\|$ (where $e$ is the solution vector, $r$ is the right hand side and $A$ is the block matrix (\ref{eq:simple_system}) ) exceeded 1.6e-9 (namely, it was 1.6e-9 ($h=3.2e-5$), 1.3e-08 ($h=8e-6$), 1.04e-07 ($h=2e-6$))





The next experiment we perform for the case of the resonance. The parameters for the problem are given in Table \ref{tab:parameters}.
\begin{table}
\begin{tabular}{lr}
$\alpha(x)$ & $\left\{\begin{array}{cc}
10, & x\leq -10,\\
-x, & -10<x\leq 5,\\
-5, & x>5.
\end{array}\right.$ \\
$\delta(x)$ & 
$\left\{\begin{array}{cc}
0, & x\leq -10,\\
4/30x+4/3,& -10<x\leq 5,\\
2, & x>5.
\end{array}\right.$ \\
$g^{inc}(-L)$ & $-2 \sqrt{2}i\exp(-22\sqrt{2}i)$\\
$\lambda$ & 
$\sqrt{10}$\\
$L$& 15\\
$H$ & 10 \\
\end{tabular}
\caption{The parameters for the problem with the resonance}
\label{tab:parameters}
\end{table}

We consider the dependence of the condition number of the block matrix on $\nu$, for several values of $h$ (see Table \ref{tab:cond_number}).
\begin{table}[ht!]
\begin{tabular}{c|ccccccccc}
\backslashbox{$h$}{$\nu$}
 & 100 & 10 & 1 & 0.1 & 1e-2 & 1e-3 & 1e-4 & 1e-8 & 0\\
 \hline
1 & 3.9634&4.3787 &4.987&36.949&42.394& 42.757 &42.79&42.793&42.793\\
\hline
0.5&      3.9931& 6.87&48.473 & 168.41  &207.34  & 209.63 & 209.83 & 209.85&  209.85\\
\hline
 0.1&      16.09  &     159.56  &     1146.1   &    8304.1   &     19169  &      20270   &     20344   &     20352   &     20352\\
 \hline
0.05&      64.046  &     637.18  &     4686.2   &     38876 &  1.4e5 &  1.58e5 &   1.58e5 &  1.58e5 &  1.58e5\\
\hline
 0.01&       1600    &   15921 & 1.2e5  & 1.1e6 & 8.3e6  & 1.8e7   & 1.93e7  & 1.93e7  & 1.93e7\\
\end{tabular}
\caption{The condition number of the matrix of the system (\ref{eq:simple_system}) for different values of $\nu$ and $h$. }
\label{tab:cond_number}
\end{table}



For $\nu=0$ the computed matrices are not singular; perhaps the bilinear form $a(u,v)$ is coercive on the chosen discrete subspace of $(L_{2}(\Omega); H^{1}(\Omega)$ (? $\alpha(x)$ enters the discretized problem only through a computation of $\int\limits_{\tau}\alpha(x)\phi_{i}(x)\phi_{j}(x)dx$, and for coarse enough meshes the discretization probably won't 'see' $\alpha(0)=0$).



At the next step we are numerically determining an optimal relation of $h$ to $\nu$. We fix $\nu$ and compute the error of the solution compared to the solution computed on the finest mesh  (with $h=2e-6$). The results are depicted in Figures \ref{fig:l2_err_e1} and \ref{fig:l2_err_e2}.


\begin{figure}
\begin{tikzpicture}
    \begin{loglogaxis}[
    	width=0.7\textwidth,
        xlabel=$h$,
        ylabel=$Error$,
        legend style={
at={(0.2,1.5)},
legend pos= south east,
anchor=south east, 
draw=none
}
]
\addplot[mark=*,blue] table {pics/result_l2e1.1.dat}; 
\addlegendentry{$\nu=1$};
\addplot[mark=*,green] table {pics/result_l2e1.0.25.dat}; 
\addlegendentry{$\nu=2^{-2}$};
\addplot[mark=*,red] table {pics/result_l2e1.0.0625.dat}; 
\addlegendentry{$\nu=2^{-4}$};
\addplot[mark=square,blue] table {pics/result_l2e1.0.015625.dat}; 
\addlegendentry{$\nu=2^{-6}$};
\addplot[mark=square,green] table {pics/result_l2e1.0.0039062.dat}; 
\addlegendentry{$\nu=2^{-8}$};
\addplot[mark=square,red] table {pics/result_l2e1.0.0039062.dat}; 
\addlegendentry{$\nu=2^{-10}$};
\addplot[mark=triangle,blue] table {pics/result_l2e1.0.00097656.dat}; 
\addlegendentry{$\nu=2^{-12}$};
\addplot[mark=triangle,green] table {pics/result_l2e1.0.00024414.dat}; 
\addlegendentry{$\nu=2^{-12}$};
\addplot[mark=triangle, red] table {pics/result_l2e1.6.1035e-05.dat};
\addlegendentry{$\nu=2^{-14}$};
\addplot[mark=*, violet] table{pics/result_l2e1.1.5259e-05.dat};
\addlegendentry{$\nu=2^{-16}$};
\end{loglogaxis}
\end{tikzpicture} 
\caption{The $L_{2}$-error of $E_{1}(x)$}
\label{fig:l2_err_e1}
\end{figure} 


\begin{figure}
\begin{tikzpicture}
    \begin{loglogaxis}[
    	width=0.7\textwidth,
        xlabel=$h$,
        ylabel=$Error$,
        legend style={
at={(0.2,1.5)},
legend pos= south east,
anchor=south east, 
draw=none
}
]
\addplot[mark=*,blue] table {pics/result_l2e2.1.dat}; 
\addlegendentry{$\nu=1$};
\addplot[mark=*,green] table {pics/result_l2e2.0.25.dat}; 
\addlegendentry{$\nu=2^{-2}$};
\addplot[mark=*,red] table {pics/result_l2e2.0.0625.dat}; 
\addlegendentry{$\nu=2^{-4}$};
\addplot[mark=square,blue] table {pics/result_l2e2.0.015625.dat}; 
\addlegendentry{$\nu=2^{-6}$};
\addplot[mark=square,green] table {pics/result_l2e2.0.0039062.dat}; 
\addlegendentry{$\nu=2^{-8}$};
\addplot[mark=square,red] table {pics/result_l2e2.0.0039062.dat}; 
\addlegendentry{$\nu=2^{-10}$};
\addplot[mark=triangle,blue] table {pics/result_l2e2.0.00097656.dat}; 
\addlegendentry{$\nu=2^{-12}$};
\addplot[mark=triangle,green] table {pics/result_l2e2.0.00024414.dat}; 
\addlegendentry{$\nu=2^{-12}$};
\addplot[mark=triangle, red] table{pics/result_l2e2.6.1035e-05.dat};
\addlegendentry{$\nu=2^{-14}$};
\addplot[mark=*, violet] table{pics/result_l2e2.1.5259e-05.dat};
\addlegendentry{$\nu=2^{-16}$};
\end{loglogaxis}
\end{tikzpicture} 
\caption{The $L_{2}$-error of $E_{2}(x)$}
\label{fig:l2_err_e2}
\end{figure} 

Let us denote by $E_{1}^{h}$ the solution $E_{1}(x)$ computed on the mesh with a width $h$, and by $E_{1}^{c}$ the solution computed on the finest mesh. We introduce 
\begin{align}
\label{eq:def_epsilon}
h_{\epsilon}=\sup\{h: \|E_{1}^{h'}-E_{1}^{c}\|<\epsilon \text{ for all } h'<h\}.
\end{align}
The computed dependence of $h_{\epsilon}$ on $\nu$ is shown in Figure \ref{}.
\begin{figure}
\begin{tikzpicture}
    \begin{loglogaxis}[
    	width=0.7\textwidth,
        xlabel=$\nu$,
        ylabel=$h_{\epsilon}$,
        legend style={
at={(0.2,1.5)},
legend pos= south east,
anchor=south east, 
draw=none
}
]
\addplot[mark=*,blue] table {pics/h1e-1.dat}; 
\addlegendentry{$\epsilon=1e-1$};
%\addplot[mark=o,red] table {pics/h1e-2.dat}; 
%\addlegendentry{$\epsilon=1e-2$};
\addplot[mark=triangle,green] table {pics/h1e-3.dat}; 
\addlegendentry{$\epsilon=1e-3$};
%\addplot[mark=square,cyan] table {pics/h1e-4.dat}; 
%\addlegendentry{$\epsilon=1e-4$};
\addplot[dashed, red] table {pics/nu1.dat}; 
\addlegendentry{$O(\nu)$};
\addplot[dashed, blue] table {pics/nu32.dat}; 
\addlegendentry{$O(\nu^{\frac{3}{2}})$};
\end{loglogaxis}
\end{tikzpicture} 
\caption{The dependence of $h_{\epsilon}$ as defined by (\ref{eq:def_epsilon}) on $\nu$.}
\end{figure}






\end{subsection}
















\end{document}  
